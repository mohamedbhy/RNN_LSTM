{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedbhy/RNN_LSTM/blob/master/RNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-iPdWCWyZ7h",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation With RNN (Recurrent Neural Network) (Fifty shades of grey style)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS6MayKSzQ1k",
        "colab_type": "text"
      },
      "source": [
        "![RNN_NETWORK](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhKHRkpyzmq2",
        "colab_type": "text"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgoE7pTImTTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install numpy\n",
        "!pip install json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb25YKFKzq6P",
        "colab_type": "text"
      },
      "source": [
        "## Import the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqBESeUdmfOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrElqZbJzwGe",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwviLbVsz1uO",
        "colab_type": "text"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quzBgqMBm4wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = tf.keras.utils.get_file('fifty_shades_of_grey.txt','https://ia800200.us.archive.org/24/items/FiftyShadesOfGrey_201603/Fifty%20Shades%20of%20Grey_djvu.txt')\n",
        "text = open(file,'rt').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxPpmCq-0AV2",
        "colab_type": "text"
      },
      "source": [
        "*Selecting First Five Chapters*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMPSoZ5gIZnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text.split(\"Chapter Five\")[0].split(\"Chapter One\")[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkCuneVR0K7O",
        "colab_type": "text"
      },
      "source": [
        "### Vectorizing Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oceqUYlw0cuX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Getting char list\n",
        "*   create array of indexes (each char has own corresponding index)\n",
        "*   create array of chars\n",
        "*   converting text to indexes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0iSIfjtnnt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "char_to_index = {c:i for i,c in enumerate(vocab)}\n",
        "index_to_char = np.array(vocab)\n",
        "text_as_int = np.array([char_to_index[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Zb-ia41X6C",
        "colab_type": "text"
      },
      "source": [
        "### Divide text into sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV6DZ-HAdhCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_length = 100\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(sequence_length+1,drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO53zQnP1yOb",
        "colab_type": "text"
      },
      "source": [
        "### Duplicate and shift sequences (Creating Input and target data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQXZzieh6GOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text,target_text\n",
        "dataset = sequences.map(split_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tra_VO12QpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6881aa2-f872-4742-9e34-e9663170bad9"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(index_to_char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(index_to_char[target_example.numpy()])))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  ' \\n\\n\\nI scowl with frustration at myself in the mirror. Damn my hair - it just won’t behave, \\nand damn'\n",
            "Target data: '\\n\\n\\nI scowl with frustration at myself in the mirror. Damn my hair - it just won’t behave, \\nand damn '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKWlu-Bq28Eu",
        "colab_type": "text"
      },
      "source": [
        "### Create Training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgo45XBJ-ScA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbiNvlEg3N1G",
        "colab_type": "text"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGtG4TOv3_tX",
        "colab_type": "text"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPfNd1NYA-Wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size,None]))\n",
        "  model.add(tf.keras.layers.LSTM(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.LSTM(rnn_units,return_sequences=True))\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "  model.add(tf.keras.layers.Dense(vocab_size))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhWywHwq4BLe",
        "colab_type": "text"
      },
      "source": [
        "### Define Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZuBQcZi6P0B",
        "colab_type": "text"
      },
      "source": [
        "**Categorical Cross Entropy:**![Categorical_cross_entropy](https://cwiki.apache.org/confluence/download/thumbnails/95651724/ce_loss.png?version=1&modificationDate=1539795211000&api=v2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdJOUog337W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels,logits):\n",
        "  return tf.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezGE1TxS4Odu",
        "colab_type": "text"
      },
      "source": [
        "### Define Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE6WqtZF4NLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6XT96Zw3UuG",
        "colab_type": "text"
      },
      "source": [
        "### Define HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLRMAArt3T2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "EPOCHS = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVya2vCa3q5n",
        "colab_type": "text"
      },
      "source": [
        "### Create Model Instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njyz6UePEjhS",
        "colab_type": "code",
        "outputId": "d75a6a93-3910-4d7e-8428-950b195a2120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "modelInstance = model(vocab_size,embedding_dim,rnn_units,BATCH_SIZE)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0603 14:40:25.957062 139892791498624 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f39e97a35f8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "W0603 14:40:26.087980 139892791498624 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f39e979d390>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7MUjlsi3x3v",
        "colab_type": "text"
      },
      "source": [
        "*Model Summary*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQHasLWxR29A",
        "colab_type": "code",
        "outputId": "7192a7a4-2a3f-4648-d85a-e923222c8993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "modelInstance.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           18432     \n",
            "_________________________________________________________________\n",
            "unified_lstm (UnifiedLSTM)   (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (64, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "unified_lstm_1 (UnifiedLSTM) (64, None, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (64, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 72)            73800     \n",
            "=================================================================\n",
            "Total params: 13,731,912\n",
            "Trainable params: 13,731,912\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYVWQslY4ZmF",
        "colab_type": "text"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh2QRgMuG8uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelInstance.compile(loss=loss,optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzstGdQn4c5l",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbr5pKpmHUM-",
        "colab_type": "code",
        "outputId": "01ae3eac-7d0b-476c-a30e-3008d3a78009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "source": [
        "modelInstance.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "17/17 [==============================] - 8s 495ms/step - loss: 3.6392\n",
            "Epoch 2/30\n",
            "17/17 [==============================] - 7s 394ms/step - loss: 3.1961\n",
            "Epoch 3/30\n",
            "17/17 [==============================] - 7s 405ms/step - loss: 3.1364\n",
            "Epoch 4/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 2.9715\n",
            "Epoch 5/30\n",
            "17/17 [==============================] - 7s 390ms/step - loss: 2.7946\n",
            "Epoch 6/30\n",
            "17/17 [==============================] - 7s 392ms/step - loss: 2.6492\n",
            "Epoch 7/30\n",
            "17/17 [==============================] - 6s 369ms/step - loss: 2.4943\n",
            "Epoch 8/30\n",
            "17/17 [==============================] - 7s 392ms/step - loss: 2.3874\n",
            "Epoch 9/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 2.3113\n",
            "Epoch 10/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 2.2415\n",
            "Epoch 11/30\n",
            "17/17 [==============================] - 7s 394ms/step - loss: 2.1721\n",
            "Epoch 12/30\n",
            "17/17 [==============================] - 7s 397ms/step - loss: 2.1110\n",
            "Epoch 13/30\n",
            "17/17 [==============================] - 7s 396ms/step - loss: 2.0486\n",
            "Epoch 14/30\n",
            "17/17 [==============================] - 7s 395ms/step - loss: 1.9865\n",
            "Epoch 15/30\n",
            "17/17 [==============================] - 7s 404ms/step - loss: 1.9267\n",
            "Epoch 16/30\n",
            "17/17 [==============================] - 7s 392ms/step - loss: 1.8715\n",
            "Epoch 17/30\n",
            "17/17 [==============================] - 6s 369ms/step - loss: 1.8165\n",
            "Epoch 18/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 1.7626\n",
            "Epoch 19/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 1.7075\n",
            "Epoch 20/30\n",
            "17/17 [==============================] - 7s 392ms/step - loss: 1.6542\n",
            "Epoch 21/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 1.6023\n",
            "Epoch 22/30\n",
            "17/17 [==============================] - 7s 391ms/step - loss: 1.5536\n",
            "Epoch 23/30\n",
            "17/17 [==============================] - 7s 394ms/step - loss: 1.5059\n",
            "Epoch 24/30\n",
            "17/17 [==============================] - 7s 396ms/step - loss: 1.4540\n",
            "Epoch 25/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 1.4084\n",
            "Epoch 26/30\n",
            "17/17 [==============================] - 5s 304ms/step - loss: 1.3597\n",
            "Epoch 27/30\n",
            "17/17 [==============================] - 7s 392ms/step - loss: 1.3068\n",
            "Epoch 28/30\n",
            "17/17 [==============================] - 7s 391ms/step - loss: 1.2545\n",
            "Epoch 29/30\n",
            "17/17 [==============================] - 7s 393ms/step - loss: 1.2067\n",
            "Epoch 30/30\n",
            "17/17 [==============================] - 7s 391ms/step - loss: 1.1608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39e7b84a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOfQ2-zh4l93",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OykpdzVD4o4p",
        "colab_type": "text"
      },
      "source": [
        "### Restore To Last Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPgYvta98yoP",
        "colab_type": "code",
        "outputId": "050f48b8-f66b-4f9b-be83-182b8dc6e489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "modelInstance = model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "modelInstance.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "modelInstance.build(tf.TensorShape([1,]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0603 15:18:19.862729 139892791498624 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f39dd373d30>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "W0603 15:18:19.993071 139892791498624 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f39dc547cc0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36CanWGS4vg2",
        "colab_type": "text"
      },
      "source": [
        "*Generate Text Function*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhWxnANA9OfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model,start_str,num_to_generate):\n",
        "  input_tensor = [char_to_index[c] for c in start_str]\n",
        "  input_tensor = tf.expand_dims(input_tensor,0)\n",
        "  generated_text = []\n",
        "  model.reset_states()\n",
        "  for i in range(num_to_generate):\n",
        "    predictions = model(input_tensor)\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "    predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "    input_tensor = tf.expand_dims([predicted_id],0)\n",
        "    generated_text.append(index_to_char[predicted_id])\n",
        "  return (start_str + ''.join(generated_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8WASxN641en",
        "colab_type": "text"
      },
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_9cV98MBbji",
        "colab_type": "code",
        "outputId": "bef841ee-1394-40ea-ccad-507b1a72d12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "print(generate_text(modelInstance,\"shape\",1000))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shaper, crefuly the fovome, and’t g. \n",
            "\n",
            "“mangh. The heav his Euld Code of dGle h. I h s pouCher mirthy in ar. I” arros the \n",
            "\n",
            "\n",
            "be sPleat it’s the wkep, at corraph. \n",
            "\n",
            "Crre” I sOhed dop bat.” \n",
            "\n",
            "Gre; of dwughes at my coffucte loothek \n",
            "hith isn attectif \n",
            "Grezy as a ty my dSmyely for a musy-: fl. Grey stechinghip, his rounlyd r hip u3 sthirga I thi- I d9aghed bacou? \n",
            "I d8er. I h t. Kire thre \n",
            "\n",
            "t’s d I sted s umpol \n",
            "this ir: \n",
            "\n",
            "Histife it h shinal, wwith \n",
            "\n",
            "I coffand we \n",
            "is koked ff axam’t ire athange: thiry tree gJ I’nt tre h’s t. \n",
            "by rengr.” Greathan \n",
            "qut if. \n",
            "spit he hinds I” eloring “me ge!” me are if \n",
            "stilled his linger as a I’t \n",
            "\n",
            "te” Thintre Gr4 StSaga2 I” \n",
            "\n",
            "I pEnterozefrinces Grey athe \n",
            "\n",
            "\n",
            "“We poulPate do a \n",
            "my ad, muridooted Cherescon- \n",
            "\n",
            "WaticoulHike-fore: is te me a Cw. \n",
            "\n",
            "p, I thirse br, drow mainthatF the fuzer h h, think, my ske dithth L‘sce dingre Ki\n",
            "\n",
            "L. He adut’s I fof anod I is \n",
            "aly fo a the” ate for ble? Squ5” I fe my withet Gy han \n",
            "ses de \n",
            "frrom Om, and \n",
            "o. Suithe umunglat \n",
            "Khe uW Kath\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}